# Generic RL Agent Training Framework

## ğŸ“‹ æ¦‚è¿°

è¿™ä¸ªæ¡†æ¶å°† Email Agent çš„è®­ç»ƒç³»ç»Ÿå½»åº•é‡æ„ä¸ºé€šç”¨çš„ RL Agent è®­ç»ƒæ¡†æ¶ï¼Œæ”¯æŒä»»æ„ç±»å‹çš„ Agent æ¥å…¥ã€‚

**é‡è¦**ï¼šæ‰€æœ‰ä»£ç å·²å®Œå…¨è¿ç§»åˆ°æ–°æ¡†æ¶ï¼Œä¸å†æœ‰å…¼å®¹å±‚ã€‚è¿™ç¡®ä¿ä»£ç åº“çš„ä¸€è‡´æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚

## ğŸ—ï¸ æ¶æ„

```
qwen3_agent/
â”œâ”€â”€ core/framework/          # é€šç”¨æ¡†æ¶å±‚
â”‚   â”œâ”€â”€ task.py             # BaseTask - ä»»åŠ¡æŠ½è±¡
â”‚   â”œâ”€â”€ agent.py            # BaseAgent - Agent æŠ½è±¡  
â”‚   â”œâ”€â”€ evaluator.py        # BaseEvaluator - è¯„ä¼°å™¨æŠ½è±¡
â”‚   â”œâ”€â”€ llm_inference.py    # LLMInference - ç»Ÿä¸€æ¨ç†æ¥å£
â”‚   â””â”€â”€ rollout.py          # generic_rollout - é€šç”¨ rollout
â”œâ”€â”€ agents/                  # å…·ä½“ Agent å®ç°
â”‚   â””â”€â”€ email_agent/        # Email Agent å®ç°
â”‚       â”œâ”€â”€ agent.py        # EmailAgent
â”‚       â”œâ”€â”€ tasks.py        # EmailTask
â”‚       â”œâ”€â”€ evaluator.py    # EmailEvaluator
â”‚       â””â”€â”€ tools.py        # Email å·¥å…·
â”œâ”€â”€ train.py                # è®­ç»ƒè„šæœ¬ï¼ˆä½¿ç”¨æ–°æ¡†æ¶ï¼‰
â””â”€â”€ benchmark.py            # è¯„ä¼°è„šæœ¬ï¼ˆä½¿ç”¨æ–°æ¡†æ¶ï¼‰
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ä½¿ç”¨ Email Agent

è®­ç»ƒå’Œè¯„ä¼°ä»£ç ç›´æ¥ä½¿ç”¨æ–°æ¡†æ¶ï¼š

```python
from qwen3_agent.core.framework import LLMInference, generic_rollout
from qwen3_agent.agents.email_agent import EmailAgent, EmailTask, EmailEvaluator

# åˆ›å»ºç»„ä»¶
task = EmailTask.from_synthetic_query(scenario)
evaluator = EmailEvaluator(verbose=True, max_turns=10)
agent = EmailAgent(evaluator=evaluator)
llm = LLMInference(model)

# æ‰§è¡Œ rollout
trajectory = await generic_rollout(
    llm=llm,
    task=task,
    agent=agent,
    evaluator=evaluator,
    max_turns=10,
    use_native_tools=True,
    verbose=True,
)
```

### åˆ›å»ºæ–°çš„ Agent

#### 1. å®šä¹‰ Task

```python
from qwen3_agent.core.framework import BaseTask

class MyTask(BaseTask):
    """è‡ªå®šä¹‰ä»»åŠ¡."""
    
    question: str
    answer: str
    
    def get_query(self) -> str:
        return self.question
    
    def get_ground_truth(self):
        return self.answer
```

#### 2. å®ç° Agent

```python
from qwen3_agent.core.framework import BaseAgent, ActionResult

class MyAgent(BaseAgent):
    """è‡ªå®šä¹‰ Agent."""
    
    def get_system_prompt(self, task: BaseTask) -> str:
        return f"You are an agent. Task: {task.get_query()}"
    
    def get_tools_schema(self) -> List[Dict]:
        return [
            {
                "type": "function",
                "function": {
                    "name": "my_tool",
                    "description": "My custom tool",
                    "parameters": {...}
                }
            }
        ]
    
    def execute_action(self, tool_name: str, tool_args: Dict, task: BaseTask) -> ActionResult:
        if tool_name == "my_tool":
            result = my_tool_implementation(**tool_args)
            return ActionResult(success=True, data=result)
        return ActionResult(success=False, error="Unknown tool")
    
    def is_terminal_action(self, tool_name: str) -> bool:
        return tool_name == "finish"
```

#### 3. å®ç° Evaluator

```python
from dataclasses import dataclass
from qwen3_agent.core.framework import BaseEvaluator, BaseRubric

@dataclass
class MyRubric(BaseRubric):
    """è‡ªå®šä¹‰è¯„ä¼°æŒ‡æ ‡."""
    answer_correct: bool = False
    num_steps: int = 0

class MyEvaluator(BaseEvaluator[MyRubric]):
    """è‡ªå®šä¹‰è¯„ä¼°å™¨."""
    
    def create_rubric(self) -> MyRubric:
        return MyRubric()
    
    async def evaluate_trajectory(self, trajectory, task, rubric) -> float:
        # è®¡ç®—æœ€ç»ˆå¥–åŠ±
        return 1.0 if rubric.answer_correct else 0.0
    
    def on_action_executed(self, rubric, tool_name, tool_args, result, task):
        # æ›´æ–°è¯„ä¼°æŒ‡æ ‡
        rubric.num_steps += 1
        if tool_name == "check_answer":
            rubric.answer_correct = (result == task.get_ground_truth())
```

#### 4. ä½¿ç”¨ Generic Rollout

```python
from qwen3_agent.core.framework import LLMInference, generic_rollout

# åˆ›å»ºç»„ä»¶
task = MyTask(id="1", question="...", answer="...")
agent = MyAgent()
evaluator = MyEvaluator()
llm = LLMInference(art_model)  # æˆ–å¤–éƒ¨æ¨¡å‹

# æ‰§è¡Œ rollout
trajectory = await generic_rollout(
    llm=llm,
    task=task,
    agent=agent,
    evaluator=evaluator,
    max_turns=10,
    use_native_tools=True,
    verbose=True,
)

print(f"Reward: {trajectory.reward}")
print(f"Metrics: {trajectory.metrics}")
```

## ğŸ”§ æ ¸å¿ƒç»„ä»¶

### 1. BaseTask

ä»»åŠ¡çš„æŠ½è±¡è¡¨ç¤ºï¼Œå®šä¹‰ï¼š
- `get_query()` - è¿”å›ç»™ Agent çš„æŸ¥è¯¢
- `get_ground_truth()` - è¿”å›æ­£ç¡®ç­”æ¡ˆï¼ˆç”¨äºè¯„ä¼°ï¼‰
- `get_context()` - è¿”å›é¢å¤–ä¸Šä¸‹æ–‡ä¿¡æ¯

### 2. BaseAgent

Agent çš„æŠ½è±¡è¡¨ç¤ºï¼Œå®šä¹‰ï¼š
- `get_system_prompt(task)` - ç”Ÿæˆç³»ç»Ÿæç¤º
- `get_tools_schema()` - è¿”å›å·¥å…·å®šä¹‰
- `execute_action(tool_name, args, task)` - æ‰§è¡Œå·¥å…·
- `is_terminal_action(tool_name)` - åˆ¤æ–­æ˜¯å¦ç»ˆæ­¢
- `parse_action(message, use_native)` - è§£æ LLM å“åº”ï¼ˆæœ‰é»˜è®¤å®ç°ï¼‰

### 3. BaseEvaluator

è¯„ä¼°å™¨çš„æŠ½è±¡è¡¨ç¤ºï¼Œå®šä¹‰ï¼š
- `create_rubric()` - åˆ›å»ºè¯„ä¼°æŒ‡æ ‡å®ä¾‹
- `evaluate_trajectory(traj, task, rubric)` - è®¡ç®—æœ€ç»ˆå¥–åŠ±ï¼ˆasyncï¼‰
- `on_action_executed(rubric, ...)` - æ¯æ­¥åæ›´æ–°æŒ‡æ ‡
- `on_parsing_error(rubric, ...)` - å¤„ç†é”™è¯¯

### 4. LLMInference

ç»Ÿä¸€çš„ LLM æ¨ç†æ¥å£ï¼š
- æ”¯æŒ ART è®­ç»ƒæ¨¡å‹
- æ”¯æŒå¤–éƒ¨æ¨¡å‹ï¼ˆOpenAIã€Anthropic ç­‰ï¼‰
- è‡ªåŠ¨å¤„ç† cachingã€token è¿½è¸ªç­‰

### 5. generic_rollout

é€šç”¨çš„ rollout æ‰§è¡Œå‡½æ•°ï¼š
- ç®¡ç†å¯¹è¯å¾ªç¯
- è°ƒç”¨ LLM ç”Ÿæˆå“åº”
- æ‰§è¡Œ Agent åŠ¨ä½œ
- è¿½è¸ªè¯„ä¼°æŒ‡æ ‡
- è®¡ç®—æœ€ç»ˆå¥–åŠ±

## ğŸ“Š LLM æ¨ç†æ¥å£ç‰¹æ€§

### æ”¯æŒå¤šç§æ¨¡å‹ç±»å‹

```python
# ART è®­ç»ƒæ¨¡å‹
llm = LLMInference(art_trainable_model)

# ART å†»ç»“æ¨¡å‹
llm = LLMInference(art_model)

# OpenAI æ¨¡å‹
llm = LLMInference("openai/gpt-4o", {"api_key": "..."})

# Anthropic æ¨¡å‹
llm = LLMInference("anthropic/claude-3-5-sonnet-20241022", {"api_key": "..."})

# è‡ªå®šä¹‰ç«¯ç‚¹
llm = LLMInference("openai/custom", {
    "base_url": "http://localhost:8000/v1",
    "api_key": "dummy"
})
```

### è‡ªåŠ¨é…ç½®

- **Caching**: è®­ç»ƒæ¨¡å‹ç¦ç”¨ç¼“å­˜ï¼Œå…¶ä»–æ¨¡å‹å¯ç”¨
- **Token è¿½è¸ª**: è‡ªåŠ¨è®°å½• prompt å’Œ completion tokens
- **é”™è¯¯å¤„ç†**: ç»Ÿä¸€çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

## âœ… ä¼˜åŠ¿

1. **å®Œå…¨è§£è€¦**: Agentã€Taskã€Evaluator ç‹¬ç«‹å®ç°
2. **æ˜“äºæ‰©å±•**: æ–° Agent åªéœ€å®ç° 4-5 ä¸ªæ¥å£
3. **LLM å¤ç”¨**: å¤–éƒ¨ Agent å¯ä»¥ä½¿ç”¨è®­ç»ƒä¸­çš„æ¨¡å‹
4. **ç±»å‹å®‰å…¨**: ä½¿ç”¨ ABC å’Œ Pydantic ä¿è¯ç±»å‹æ£€æŸ¥
5. **ä»£ç ä¸€è‡´**: æ‰€æœ‰ä»£ç ä½¿ç”¨ç»Ÿä¸€çš„æ–°æ¡†æ¶ï¼Œæ— æŠ€æœ¯å€ºåŠ¡

## ğŸ“ ç¤ºä¾‹ï¼šæ–°æ¶æ„

### è®­ç»ƒè„šæœ¬ (train.py)

```python
from qwen3_agent.core.framework import LLMInference, generic_rollout
from qwen3_agent.agents.email_agent import EmailAgent, EmailTask, EmailEvaluator

# åˆ›å»ºç»„ä»¶
evaluator = EmailEvaluator(...)
agent = EmailAgent(evaluator=evaluator)
llm = LLMInference(model)

# ç”Ÿæˆ trajectories
groups = await art.gather_trajectory_groups(
    (
        art.TrajectoryGroup(
            (
                generic_rollout(
                    llm=llm,
                    task=EmailTask.from_synthetic_query(scenario),
                    agent=agent,
                    evaluator=evaluator,
                    ...
                )
                for _ in range(trajectories_per_group)
            )
        )
        for scenario in batch
    )
)
```

### è¯„ä¼°è„šæœ¬ (benchmark.py)

```python
from qwen3_agent.core.framework import LLMInference, generic_rollout
from qwen3_agent.agents.email_agent import EmailAgent, EmailTask, EmailEvaluator

# åˆ›å»ºç»„ä»¶
evaluator = EmailEvaluator(...)
agent = EmailAgent(evaluator=evaluator)
llm = LLMInference(model)

# è¿è¡Œè¯„ä¼°
trajectories = await gather_trajectories(
    (
        generic_rollout(
            llm=llm,
            task=EmailTask.from_synthetic_query(scenario),
            agent=agent,
            evaluator=evaluator,
            ...
        )
        for scenario in scenarios
    )
)
```

## ğŸ§ª æµ‹è¯•

è¿è¡Œæµ‹è¯•è„šæœ¬ï¼š

```bash
uv run python test_framework.py
```

æµ‹è¯•å†…å®¹ï¼š
1. âœ… æ¡†æ¶åŸºç¡€åŠŸèƒ½
2. âœ… LLM æ¨ç†æ¥å£
3. âœ… Agent æ‰§è¡Œé€»è¾‘
4. âœ… è¯„ä¼°å™¨å¥–åŠ±è®¡ç®—
5. âœ… æ¨¡å—é›†æˆæµ‹è¯•

## ğŸ“š æ‰©å±•é˜…è¯»

- æŸ¥çœ‹ `qwen3_agent/agents/email_agent/` äº†è§£å®Œæ•´çš„ Agent å®ç°ç¤ºä¾‹
- æŸ¥çœ‹ `qwen3_agent/core/framework/` äº†è§£æ¡†æ¶æ¥å£å®šä¹‰
- æŸ¥çœ‹ `examples/simple_math_agent.py` äº†è§£å¦‚ä½•åˆ›å»ºæ–° Agent

## ğŸ¤ è´¡çŒ®æ–° Agent

1. åœ¨ `qwen3_agent/agents/` ä¸‹åˆ›å»ºæ–°ç›®å½•
2. å®ç° `BaseTask`ã€`BaseAgent`ã€`BaseEvaluator`
3. æ·»åŠ æµ‹è¯•è„šæœ¬
4. æ›´æ–°æ–‡æ¡£

æ¬¢è¿è´¡çŒ®ï¼
