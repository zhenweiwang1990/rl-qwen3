#!/usr/bin/env python3
"""
å°† benchmark-queries.csv ä¸­çš„ answer å­—æ®µé‡Œçš„ content å­—æ®µåˆå¹¶æˆæ¯ä¸ªé—®é¢˜ä¸€ä¸ªæ•°ç»„ã€‚
åŽ»æŽ‰ batch å±‚çº§ï¼Œç›´æŽ¥æ‹å¹³æ‰€æœ‰ contentã€‚
"""

import csv
import json
from pathlib import Path


def flatten_answers(input_file: str, output_file: str):
    """
    è¯»å– benchmark-queries.csvï¼Œå°† answer ä¸­çš„æ‰€æœ‰ content æ‹å¹³æˆä¸€ä¸ªæ•°ç»„ã€‚
    
    Args:
        input_file: è¾“å…¥çš„ CSV æ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºçš„ CSV æ–‡ä»¶è·¯å¾„
    """
    
    with open(input_file, 'r', encoding='utf-8') as f_in:
        reader = csv.DictReader(f_in)
        
        # å‡†å¤‡è¾“å‡ºæ•°æ®
        output_rows = []
        
        for row in reader:
            question_id = row['id']
            query = row['query']
            answer_json = row['answer']
            batch = row['batch']
            updated_at = row['updated_at']
            
            # è§£æž answer JSON
            try:
                answer_data = json.loads(answer_json)
                
                # æ‹å¹³æ‰€æœ‰ batch çš„ content
                flattened_content = []
                for item in answer_data:
                    if 'content' in item:
                        flattened_content.extend(item['content'])
                
                # ä¿å­˜ç»“æžœ
                output_rows.append({
                    'id': question_id,
                    'query': query,
                    'content': json.dumps(flattened_content, ensure_ascii=False),
                    'content_count': len(flattened_content),
                    'batch': batch,
                    'updated_at': updated_at
                })
                
            except json.JSONDecodeError as e:
                print(f"è­¦å‘Š: ID {question_id} çš„ answer å­—æ®µè§£æžå¤±è´¥: {e}")
                output_rows.append({
                    'id': question_id,
                    'query': query,
                    'content': '[]',
                    'content_count': 0,
                    'batch': batch,
                    'updated_at': updated_at
                })
        
        # å†™å…¥è¾“å‡ºæ–‡ä»¶
        with open(output_file, 'w', encoding='utf-8', newline='') as f_out:
            fieldnames = ['id', 'query', 'content', 'content_count', 'batch', 'updated_at']
            writer = csv.DictWriter(f_out, fieldnames=fieldnames)
            
            writer.writeheader()
            writer.writerows(output_rows)
    
    print(f"âœ… å¤„ç†å®Œæˆ!")
    print(f"   è¾“å…¥æ–‡ä»¶: {input_file}")
    print(f"   è¾“å‡ºæ–‡ä»¶: {output_file}")
    print(f"   å¤„ç†äº† {len(output_rows)} ä¸ªé—®é¢˜")


def main():
    # æ–‡ä»¶è·¯å¾„
    data_dir = Path(__file__).parent / 'data'
    input_file = data_dir / 'benchmark-queries.csv'
    output_file = data_dir / 'benchmark-queries-flattened.csv'
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not input_file.exists():
        print(f"âŒ é”™è¯¯: è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨ - {input_file}")
        return
    
    # æ‰§è¡Œæ‹å¹³æ“ä½œ
    flatten_answers(str(input_file), str(output_file))
    
    # æ˜¾ç¤ºç¤ºä¾‹
    print("\nðŸ“Š è¾“å‡ºç¤ºä¾‹ (å‰3è¡Œ):")
    with open(output_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for i, row in enumerate(reader):
            if i >= 3:
                break
            content = json.loads(row['content'])
            print(f"\nID: {row['id']}")
            print(f"Query: {row['query'][:80]}...")
            print(f"Content Count: {row['content_count']}")
            print(f"First 5 items: {content[:5]}")


if __name__ == '__main__':
    main()

